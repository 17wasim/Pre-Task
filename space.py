# -*- coding: utf-8 -*-
"""Space.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10RfpeplL_Z4DLe3nCD52u4MYebRdI7GP
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

train_data = pd.read_csv('/content/drive/MyDrive/train.csv')
test_data = pd.read_csv('/content/drive/MyDrive/test.csv')

train_data.head()

test_data.head()

columns_to_check = ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination' , 'VIP']
for column in columns_to_check:
    unique_values = train_data[column].unique()
    print(f"Unique values in {column}: {unique_values}")

sns.countplot(x='Transported', data=train_data)
plt.title('Distribution of Transported')
plt.show()

X_train = train_data.drop(['PassengerId', 'Name', 'Transported'], axis=1)
y_train = train_data['Transported']
X_test = test_data.drop(['PassengerId', 'Name'], axis=1)

imputer = SimpleImputer(strategy='most_frequent')
X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)
X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)

# Convert categorical features to numeric representations
categorical_cols = ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP']
label_encoders = {}
for col in categorical_cols:
    label_encoders[col] = LabelEncoder()
    label_encoders[col].fit(pd.concat([X_train_imputed[col], X_test_imputed[col]]))
    X_train_imputed[col] = label_encoders[col].transform(X_train_imputed[col])
    X_test_imputed[col] = label_encoders[col].transform(X_test_imputed[col])

# One-hot encode categorical variables separately for training and test data
X_train_encoded = pd.get_dummies(X_train_imputed, columns=categorical_cols, prefix=categorical_cols, prefix_sep='_')
X_test_encoded = pd.get_dummies(X_test_imputed, columns=categorical_cols, prefix=categorical_cols, prefix_sep='_')

# Align the features to ensure consistency in column names
X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join='left', axis=1, fill_value=0)

print(X_train_encoded.shape)
print(X_test_encoded.shape)

# Perform train-test split
X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_encoded, y_train, test_size=0.2, random_state=42)

tsne = TSNE(n_components=2, random_state=42)
X_train_tsne = tsne.fit_transform(X_train_encoded)

# Visualize t-SNE
plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], c=y_train, cmap='viridis')
plt.title("t-SNE Visualization of Encoded Training Data")
plt.xlabel("t-SNE Dimension 1")
plt.ylabel("t-SNE Dimension 2")
plt.colorbar()
plt.show()

# Train the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train_split, y_train_split)

# Make predictions
y_train_pred = model.predict(X_train_split)
y_val_pred = model.predict(X_val_split)
y_test_pred = model.predict(X_test_encoded)

# Compute accuracy scores
train_accuracy = accuracy_score(y_train_split, y_train_pred)
val_accuracy = accuracy_score(y_val_split, y_val_pred)

print("Training Accuracy:", train_accuracy)
print("Validation Accuracy:", val_accuracy)

# Create prediction dataframes
test_predictions = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Transported': y_test_pred})

#  Save predictions to CSV files
test_predictions.to_csv('test_predictions1.csv', index=False)

#Train the model
model = RandomForestClassifier(random_state=42)

# Perform cross-validation
cv_scores = cross_val_score(model, X_train_split, y_train_split, cv=5)

# Print cross-validation scores
print("Cross-Validation Scores:", cv_scores)
print("Mean Cross-Validation Score:", np.mean(cv_scores))
print("Standard Deviation of Cross-Validation Scores:", np.std(cv_scores))

# Train the model on the entire training set
model.fit(X_train_split, y_train_split)

#  Make predictions on the test set
y_test_pred = model.predict(X_test_encoded)

test_predictions = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Transported': y_test_pred})

test_predictions.to_csv('test_predictions2.csv', index=False)

from sklearn.neighbors import KNeighborsClassifier

X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_encoded, y_train, test_size=0.2, random_state=42)

#  Train and evaluate KNN classification with different values of k
k_values = [2, 5, 7]  # Example values of k
for k in k_values:
    # Train the model
    model = KNeighborsClassifier(n_neighbors=k)
    model.fit(X_train_split, y_train_split)

    # Make predictions
    y_train_pred = model.predict(X_train_split)
    y_val_pred = model.predict(X_val_split)

    # Compute accuracy scores
    train_accuracy = accuracy_score(y_train_split, y_train_pred)
    val_accuracy = accuracy_score(y_val_split, y_val_pred)

    print(f"K = {k}:")
    print("Training Accuracy:", train_accuracy)
    print("Validation Accuracy:", val_accuracy)
    print()

#Choose the best k based on validation performance and make predictions with that k
best_k = 7  # Choose the best k based on validation performance

# Train the model with the best k
model = KNeighborsClassifier(n_neighbors=best_k)
model.fit(X_train_encoded, y_train)

# Make predictions on the test data
y_test_pred = model.predict(X_test_encoded)

#  Create prediction dataframe
test_predictions = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Transported': y_test_pred})

# Save predictions to CSV file
test_predictions.to_csv('test_predictions3.csv', index=False)